{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a36777-480d-4dc1-94df-5944180dfdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs336_basics.model import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f7b35-6dd6-4716-a951-f1dff3f88449",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT2 = {\"vocab_size\": 50257, \"context_length\": 1024, \"d_ff\": 6400}\n",
    "CONFIGS = {\"XL\": {\"num_layers\": 48, \"d_model\": 1600, \"num_heads\": 25},\n",
    "           \"XL-CONT\": {\"context_length\": 16384},\n",
    "           \"large\": {\"num_layers\": 36, \"d_model\": 1280, \"num_heads\": 20},\n",
    "           \"medium\": {\"num_layers\": 24, \"d_model\": 1024, \"num_heads\": 16},\n",
    "           \"small\": {\"num_layers\": 12, \"d_model\": 768, \"num_heads\": 12},\n",
    "          }\n",
    "CONFIGS[\"XL-CONT\"].update(CONFIGS[\"XL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a854a9a-4f72-42c9-b85b-b3968bbf1781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model(vocab_size, context_length, d_ff, num_layers, d_model, num_heads):\n",
    "    emb_params = vocab_size * d_model\n",
    "    ln_params = d_model\n",
    "    sa_params = 4 * d_model * d_model\n",
    "    ffn_params = 3 * d_model * d_ff\n",
    "    layer_params = 2 * ln_params + sa_params + ffn_params\n",
    "    lm_head_params = d_model * vocab_size\n",
    "    exp_params = emb_params + num_layers * layer_params + ln_params + lm_head_params\n",
    "\n",
    "    model = Transformer(rope_theta=10000, vocab_size=vocab_size, context_length=context_length, d_ff=d_ff, \n",
    "                        num_layers=num_layers, d_model=d_model, num_heads=num_heads)\n",
    "    act_params = sum(p.numel() for p in model.parameters())\n",
    "    assert exp_params == act_params    \n",
    "\n",
    "    print(f\"Number of parameters = {exp_params:,}, memory = {exp_params * 4:,} (not counting RoPE buffers and other overhead)\")\n",
    "    print(f\"Formula estimate of FLOPs: 2 * context_length * num_params = {2 * context_length * exp_params:,}\")\n",
    "    \n",
    "    # Layer FLOPS\n",
    "    qkv_flops = 2 * context_length * d_model * 3 * d_model\n",
    "    scaled_dp_attn_flops = 2 * 2 * context_length * context_length * d_model  # compute and apply the score matrix\n",
    "    out_flops = 2 * context_length * d_model * d_model\n",
    "    attn_flops = qkv_flops + scaled_dp_attn_flops + out_flops  # 8 * context_length * d_model^2 + 4 * context_length^2 * d_model\n",
    "    ffn_flops = 2 * 3 * context_length * d_model * d_ff  # 6 * context_length * d_model * d_ff\n",
    "    layer_flops = attn_flops + ffn_flops\n",
    "\n",
    "    # Proportions\n",
    "    attn_flops_perc = attn_flops / layer_flops * 100\n",
    "    qkv_flops_perc = qkv_flops / layer_flops * 100\n",
    "    scaled_dp_attn_flops_perc = scaled_dp_attn_flops / layer_flops * 100\n",
    "    out_flops_perc = out_flops / layer_flops * 100\n",
    "    ffn_flops_perc = ffn_flops / layer_flops * 100\n",
    "    \n",
    "    # Transformer FLOPS\n",
    "    all_layers_flops = num_layers * layer_flops\n",
    "    lm_head_flops = context_length * d_model * vocab_size\n",
    "    transformer_flops = all_layers_flops + lm_head_flops\n",
    "\n",
    "    # Proportions\n",
    "    all_layers_flops_perc = all_layers_flops / transformer_flops * 100\n",
    "    lm_head_flops_perc = lm_head_flops / transformer_flops * 100 \n",
    "\n",
    "    print(\"\\nManual estimate of FLOPs\")\n",
    "    print(f\"Transformer: {transformer_flops:,} ({num_layers:,} layers: \"\n",
    "          f\"{all_layers_flops_perc:.1f}%, lm_head: {lm_head_flops_perc:.1f}%)\")\n",
    "    print(f\"  Layer: {layer_flops:,}\")\n",
    "    print(f\"    Attention: {attn_flops_perc:.1f}% (qkv: {qkv_flops_perc:.1f}%, \"\n",
    "          f\"scaled_dp_attn: {scaled_dp_attn_flops_perc:.1f}%, out: {out_flops_perc:.1f}%)\")\n",
    "    print(f\"    FFN: {ffn_flops_perc:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a687b6ff-5a4d-4976-b345-c3ab4e13e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, config in CONFIGS.items():\n",
    "    print(f\"\\n======== {name} ========\\n\")\n",
    "    analyze_model(**(GPT2 | config))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
